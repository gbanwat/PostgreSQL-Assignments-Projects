Absolutely â€” here is a **clean, combined README** that gives a **short, polished description of each assignment**, keeping the style consistent and professional.
This is meant to serve as a **single master README** for your entire DTSC660 portfolio.

---

# ğŸ“˜ DTSC660 â€“ SQL Assignment Portfolio

A collection of all major SQL assignments completed for **DTSC660: Data and Database Management with SQL**.
Each assignment demonstrates progressively advanced SQL concepts â€” from database creation to data cleaning and analytical querying â€” using PostgreSQL.

---

## ğŸ§± **Assignment 1 â€” Database & Table Creation (Auto Parts Unlimited & Holy Grounds)**

**Focus:** Database design, schema creation, data types, business-rule implementation
This assignment involved building two complete PostgreSQL databases for two mock clients: **Auto Parts Unlimited** and **Holy Grounds Coffee Shop**.
Each database includes multiple tables designed according to strict business rules, correct PostgreSQL data types, numeric precision, and formatting constraints.
This assignment demonstrates foundational SQL skills in schema design, table creation, and data validation.

---

## ğŸ—‚ï¸ **Assignment 2 â€” SQL Query Practice (GitHub Dataset Analysis)**

**Focus:** Filtering, sorting, pattern matching, DISTINCT, NULL handling
Using a large dataset of GitHub repositories, this assignment focused on practicing core SQL querying skills.
Fifteen SQL queries were written to explore topics, filter repositories by attributes, sort results, extract unique values, and analyze repository characteristics.
The work emphasizes accuracy, clean query structure, and PostgreSQL-compliant syntax.

---

## ğŸ“Š **Assignment 3 â€” Bitcoin Transaction Analysis (2009 Dataset)**

**Focus:** Mathematical operations, aggregations, column transformations, statistical insight generation
This assignment involved importing a historical Bitcoin transaction dataset and performing analytical queries such as calculating averages, totals, peak market metrics, and value transformations.
It highlights SQLâ€™s role in financial analytics, working with real-world numeric data, and applying PostgreSQL operations for insightful reporting.

---

## ğŸ¦ **Assignment 4 â€” Banking Database Creation & Multi-Table Queries**

**Focus:** DDL creation, relational modeling, constraints, cascades, multi-table joins
Students designed a full **banking database schema** with six interconnected tables.
The work required implementing primary keys, foreign keys, CHECK constraints, CASCADE rules, default values, and proper data types.
After importing data, multiple multi-table queries were developed to analyze customers, accounts, loans, and branches.

---

## ğŸ¦ **Assignment 5 â€” Advanced Banking Queries**

**Focus:** Subqueries, conditional filters, join-restricted logic, set-based reasoning
Building on the Assignment 4 database, this assignment applied advanced SQL querying techniques.
Students used subqueries, conditional matching, and no-join logic (where required) to identify customer behaviors such as loan-only customers, Brooklyn branch usage, and city-matched accounts.
The assignment strengthens analytical SQL logic with more complex relational conditions.

---

## ğŸ“Š **Assignment 6 â€” Consumer Sales Trend Analysis**

**Focus:** Aggregation, grouping, revenue analysis, multi-dimensional analytics
Using a large consumer-spending dataset, students created and imported a PostgreSQL table, then wrote analytical queries to explore sales trends.
Tasks included computing revenue leaders, margin calculations, age-based purchasing patterns, and sub-category insights.
This assignment demonstrates SQLâ€™s ability to drive business intelligence and data-driven retail insights.

---

## ğŸ§¹ **Assignment 7 â€” Data Cleaning & Preparation (Data Scientist Salaries Dataset)**

**Focus:** Data cleaning, standardization, missing-value handling, transformation logic
Using the **Data Scientist Salaries** dataset from Kaggle, this assignment required performing full SQL-based data wrangling.
Tasks included:
âœ” Creating backup tables
âœ” Handling missing or inconsistent values
âœ” Standardizing categorical fields (e.g., experience levels, company sizes)
âœ” Fixing formatting issues
âœ” Applying one additional cleaning method (e.g., trimming, type casting, normalization)
This assignment demonstrates real-world data-cleaning practices essential for analytics.

---

## ğŸ¯ **Overall Course Outcomes**

Across all assignments, this portfolio demonstrates mastery of:

* SQL database design (DDL & schema creation)
* Data importing and validation
* Filtering, grouping, and statistical computations
* Advanced subqueries and relational reasoning
* Large-scale retail and financial data analysis
* Data cleaning and standardization workflows
* Strict PostgreSQL compliance for academic and production-level use

---
